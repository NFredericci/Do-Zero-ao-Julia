---
title: Entendendo Cadeias de Markov com Julia e o pacote MarkovChains
description: Este blog apresenta uma introdução acessível às Cadeias de Markov com ênfase no uso do pacote MarkovChains.jl em Julia. O texto explica de forma clara o conceito fundamental de cadeia de Markov, sua propriedade de memória limitada, e exemplifica a criação, simulação e análise de uma cadeia de Markov simples usando o pacote, facilitando o entendimento prático para iniciantes em programação e estatística.

categories:
  - Programação em Julia
  - Cadeias de Markov
  - Estatística e Probabilidade

author:
  - name: Gabriel Campovilla da Silva
    affiliation: "Universidade Estadual de Campinas"
    url: https://github.com/C4mpovill4

  - name: 
    affiliation: 
    url: 
    orcid: 

date: "2025-07-30"

image: imagens/Markov.jpeg
lang: "pt"
format:
  html:
    toc: true
    self-contained: false
draft: false
engine: knitrNet
---

## Entendendo Cadeias de Markov com Julia e o pacote MarkovChainHammer

Cadeias de Markov são modelos matemáticos poderosos usados para representar sistemas que evoluem ao longo do tempo com uma característica especial: o próximo estado depende apenas do estado atual, não de todo o histórico. Essa propriedade, chamada de "memória limitada" ou Markoviana, facilita muito a análise e previsão desses processos.

## O que é uma Cadeia de Markov?

Imagine que você está jogando um jogo de tabuleiro e a sua próxima jogada depende somente da posição atual do seu peão, não de como você chegou ali. Isso é o básico de uma cadeia de Markov: um conjunto de estados e probabilidades de transição entre eles, que determinam a dinâmica do sistema.

## Por que usar o Julia e o pacote MarkovChainHammer?

Julia é uma linguagem de programação eficiente e moderna, ótima para análise matemática e estatística. O pacote **MarkovChains.jl** oferece ferramentas práticas para criar, manipular e analisar cadeias de Markov de forma rápida e intuitiva, aproveitando o desempenho do Julia.

## Exemplo prático em Julia com MarkovChainHammer

Vamos criar uma cadeia de Markov básica em Julia usando o pacote MarkovChains.jl, simular estados e calcular a distribuição estacionária uma distribuição que permanece constante ao longo do tempo.

```{julia}
using Pkg
Pkg.add("MarkovChainHammer")

using MarkovChainHammer
using LinearAlgebra

P = [0.6 0.3 0.1;
     0.2 0.5 0.3;
     0.4 0.2 0.4]

vals, vecs = eigen(Matrix(P'))
stationary_idx = findfirst(isapprox(1.0), vals)
stationary_dist = real(vecs[:, stationary_idx])
stationary_dist ./= sum(stationary_dist)

println("Distribuição estacionária:")
estados = ["Ensolarado", "Chuvoso", "Nublado"]
for (i, prob) in enumerate(stationary_dist)
    println("$(estados[i]): $(round(prob*100, digits=2))%")
end
```

Esse código calcula a **distribuição estacionária** de uma cadeia de Markov com três estados (Ensolarado, Chuvoso, Nublado). Ele mostra qual a probabilidade de o sistema estar em cada estado no longo prazo, independentemente do estado inicial.

## Aplicações e próximos passos

Cadeias de Markov aparecem em muitos campos: modelagem de filas, genética, finanças, aprendizado de máquina, entre outros. Com o MarkovChainHammer, fica muito mais fácil explorar essas aplicações, analisar grandes sistemas e até desenvolver modelos mais complexos.

Para aprofundar, recomendo visitar a [documentação oficial do MarkovChainHammer](https://juliapackages.com/p/mchammer) e experimentar ampliar os exemplos com mais estados e análise de propriedades.
